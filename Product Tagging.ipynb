{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Product Tagging.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"MTH2YnioHcGr","colab_type":"text"},"cell_type":"markdown","source":["### **Mounting Google Drive....**"]},{"metadata":{"id":"33ovo4w4zKlg","colab_type":"code","colab":{}},"cell_type":"code","source":["# Install a Drive FUSE wrapper.\n","# https://github.com/astrada/google-drive-ocamlfuse\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zkoyVewmzRqy","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate auth tokens for Colab\n","from google.colab import auth\n","auth.authenticate_user()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fBW9TpWAzXBO","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate creds for the Drive FUSE library.\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","# Work around misordering of STREAM and STDIN in Jupyter.\n","# https://github.com/jupyter/notebook/issues/3159\n","prompt = !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass(prompt[0] + '\\n\\nEnter verification code: ')\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HA0JUVTpzZNe","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a directory and mount Google Drive using that directory.\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W_IeD0VGJ-tc","colab_type":"code","colab":{}},"cell_type":"code","source":["print ('Files in Drive:')\n","!ls drive/"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UA1E0dyl0h55","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","a='drive/ProductTagging'\n","b='dataset/train'\n","os.listdir(a+'/'+b)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vrvJNVasQHje","colab_type":"text"},"cell_type":"markdown","source":["### Installing the required libraries"]},{"metadata":{"id":"68ELwcg9PSVd","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install keras\n","!pip install scikit-learn\n","!pip install numpy\n","!pip install glob\n","!pip install h5py\n","!pip install os\n","!pip install json\n","!pip install Pillow\n","!pip install pickle"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C2faCBcaHyOG","colab_type":"text"},"cell_type":"markdown","source":["### **Extracting features from images in dataset....**"]},{"metadata":{"id":"R9GdFEVNGom6","colab_type":"code","outputId":"fcb89474-67fd-4b02-88b3-1ff92db75c50","executionInfo":{"status":"ok","timestamp":1550614939300,"user_tz":-330,"elapsed":4313,"user":{"displayName":"Aaditya Vikram","photoUrl":"https://lh4.googleusercontent.com/-svTvRUaInsY/AAAAAAAAAAI/AAAAAAAAA1I/5p-p1X5lAxU/s64/photo.jpg","userId":"11762200014277312603"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras.preprocessing import image\n","from keras.models import Model\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","import glob\n","import h5py\n","import os\n","import json"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"YiJcXDgtGreL","colab_type":"code","colab":{}},"cell_type":"code","source":["train_path = \"drive/ProductTagging/dataset/train\"\n","features_path = \"drive/ProductTagging/output/features.h5\"\n","labels_path = \"drive/ProductTagging/output/labels.h5\"\n","test_size = 0.30\n","model_path = \"drive/ProductTagging/output/model\"\n","base_model = VGG16(weights=\"imagenet\")                                              #loading pretrained vgg16 model\n","model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)  #retraining the last fully connected layer\n","image_size = (224, 224)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"beks7FR7G4qh","colab_type":"code","colab":{}},"cell_type":"code","source":["print (\"Loaded the model\")\n","\n","train_labels = os.listdir(train_path)\n","\n","le = LabelEncoder()                                                                 #encode the labels\n","le.fit([z for z in train_labels])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ujReS46VG7Se","colab_type":"code","colab":{}},"cell_type":"code","source":["# variables to hold features and labels\n","features = []\n","labels   = []\n","\n","# loop over all the labels in the folder\n","count = 1\n","for i, label in enumerate(train_labels):\n","    cur_path = train_path + \"/\" + label\n","    count = 1\n","    for e in [cur_path + \"\\\\*.jpg\",cur_path + \"\\\\*.png\"]:\n","      for image_path in glob.glob(e):\n","          img = image.load_img(image_path, target_size=image_size)\n","          x = image.img_to_array(img)\n","          x = np.expand_dims(x, axis=0)\n","          x = preprocess_input(x)\n","          feature = model.predict(x)\n","          flat = feature.flatten()\n","          features.append(flat)\n","          labels.append(label)\n","          print (\"Processed image %s in this category\"%count)\n","          count += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tKf4AGznG9vk","colab_type":"code","colab":{}},"cell_type":"code","source":["le = LabelEncoder()                                                                 #encode the labels\n","le_labels = le.fit_transform(labels)\n","\n","h5f_data = h5py.File(features_path, 'w')\n","h5f_data.create_dataset('dataset_1', data=np.array(features))                       #saving the features\n","\n","h5f_label = h5py.File(labels_path, 'w')\n","h5f_label.create_dataset('dataset_1', data=np.array(le_labels))                     #saving the labels\n","\n","h5f_data.close()\n","h5f_label.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wBvoFHRVG_3n","colab_type":"code","colab":{}},"cell_type":"code","source":["model_json = model.to_json()                                                        #saving model\n","with open(model_path + str(test_size) + \".json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","print(\"Saved model\")\n","\n","model.save_weights(model_path + str(test_size) + \".h5\")                             #saving weights\n","print(\"Saved weights\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9bEizhkFH8yV","colab_type":"text"},"cell_type":"markdown","source":["### **Retraining the top layer of pretrained VGG16 model....**"]},{"metadata":{"id":"EQ5x8DLbHEQC","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","import h5py\n","import os\n","import pickle"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vMRc1OnnHFGP","colab_type":"code","colab":{}},"cell_type":"code","source":["test_size = 0.30\n","seed = 9\n","features_path = \"drive/ProductTagging/output/features.h5\"\n","labels_path = \"drive/ProductTagging/output/labels.h5\"\n","classifier_path = \"drive/ProductTagging/output/classifier.pickle\"\n","train_path = \"drive/ProductTagging/dataset/train\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"PEaSpe-3HHnv","colab_type":"code","colab":{}},"cell_type":"code","source":["h5f_data  = h5py.File(features_path, 'r')               # import features and labels\n","h5f_label = h5py.File(labels_path, 'r')\n","\n","features_string = h5f_data['dataset_1']\n","labels_string   = h5f_label['dataset_1']\n","\n","features = np.array(features_string)\n","labels   = np.array(labels_string)\n","\n","h5f_data.close()\n","h5f_label.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eEy0L9bbHM6k","colab_type":"code","colab":{}},"cell_type":"code","source":["print(\"Training started\")\n","(trainData, testData, trainLabels, testLabels) = train_test_split(np.array(features),np.array(labels),test_size=test_size,random_state=seed) # split the training and testing data\n","\n","model = LogisticRegression(random_state=seed)\n","print (\"Model created\")\n","model.fit(trainData, trainLabels)\n","\n","\n","print ()\n","accuracy = 0\n","\n","for (label, features) in zip(testLabels, testData):\t\t\t\t\t\t\t    #loop over test data\n","\tpredictions = model.predict_proba(np.atleast_2d(features))[0]\t\t\t#predict the probability of each class label\n","\tpredictions = np.argsort(predictions)[::-1][:5]\n","\n","\tif label == predictions[0]:\n","\t\taccuracy += 1\n","\n","accuracy = (accuracy / float(len(testLabels))) * 100\t\t\t\t\t\t    #convert accuracies to percentages\n","\n","print('Final Accuracy -> {:.2f}%\\n'.format(accuracy))\n","\n","preds = model.predict(testData)                                     #evaluate the model on test data\n","\n","print(\"Saving model\")\n","pickle.dump(model, open(classifier_path, 'wb'))                     #save the classifier"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ncmpxyRlIEFp","colab_type":"text"},"cell_type":"markdown","source":["### **Predicting labels of test images....**"]},{"metadata":{"id":"xW1GaMw0HQsr","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras.preprocessing import image\n","from keras.models import Model\n","import numpy as np\n","import os\n","import pickle\n","from PIL import Image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E1ALTpDqHSRd","colab_type":"code","outputId":"1b12de69-068a-43e5-8b75-b4f5756fddfa","executionInfo":{"status":"ok","timestamp":1550621369944,"user_tz":-330,"elapsed":1187,"user":{"displayName":"Aaditya Vikram","photoUrl":"https://lh4.googleusercontent.com/-svTvRUaInsY/AAAAAAAAAAI/AAAAAAAAA1I/5p-p1X5lAxU/s64/photo.jpg","userId":"11762200014277312603"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["train_path = \"drive/ProductTagging/dataset/train\"\n","test_path = \"drive/ProductTagging/dataset/test\"\n","classifier_path = \"drive/ProductTagging/output/classifier.pickle\"\n","\n","print(\"Loaded the classifier\")                           #loaded the trained logistic regression classifier\n","classifier = pickle.load(open(classifier_path, 'rb'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loaded the classifier\n"],"name":"stdout"}]},{"metadata":{"id":"pgfh26K-HT-X","colab_type":"code","colab":{}},"cell_type":"code","source":["base_model = VGG16(weights=\"imagenet\")                                              #loaded the pretrained vgg16 model\n","model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)  #retraining the last fully connected layer\n","image_size = (224, 224)\n","\n","train_labels = os.listdir(train_path)\n","\n","test_images = os.listdir(test_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vNrdwPkNHVka","colab_type":"code","colab":{}},"cell_type":"code","source":["f=open(\"drive/ProductTagging/predicted_labels.txt\",'w+')\n","\n","for image_path in test_images:\n","    path = test_path + \"/\" + image_path\n","    try:\n","        Image.open(path).verify()                                                   #checking if image is corrupt or not\n","        img = image.load_img(path, target_size=image_size)\n","        x = image.img_to_array(img)\n","        x = np.expand_dims(x, axis=0)\n","        x = preprocess_input(x)\n","        feature = model.predict(x)\n","        flat = feature.flatten()\n","        flat = np.expand_dims(flat, axis=0)\n","        preds = classifier.predict(flat)\n","        print(image_path + \" -> \" + train_labels[preds[0]])                         #Predicting label of test images\n","        f.write(image_path + \" -> \" + train_labels[preds[0]]+'\\n')\n","    except Exception:\n","        print(image_path + \" -> Corrupt Image\")\n","        f.write(image_path + \" -> Corrupt Image\"+'\\n')\n","f.close()"],"execution_count":0,"outputs":[]}]}